{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revirevy/RAG_NIX/blob/main/RAG_FOR_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "chatbot\n"
      ],
      "metadata": {
        "id": "ue8iNuly1ZeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q uv PyPDF2 sentence-transformers langchain faiss-cpu groq\n"
      ],
      "metadata": {
        "id": "c48Qeuo71pl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763d44a2-0cd7-40dc-8c9c-a91bc47413df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QqIc1roy5NCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -U langchain-community -q --system transformers sentence_transformers numpy PyPDF2  langchain faiss-cpu groq --no-cache-dir\n"
      ],
      "metadata": {
        "id": "IgDST50w2bad"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -U -q --system sentence_transformers numpy transformers"
      ],
      "metadata": {
        "id": "cmvH3bki5nN6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q --system"
      ],
      "metadata": {
        "id": "nFVxoha46zc9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show numpy"
      ],
      "metadata": {
        "id": "YuLacPHD5V09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC9PaMXJ51RB",
        "outputId": "a10f66f9-d60c-4233-afc4-f62ddeb4f315"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: sentence-transformers\n",
            "Version: 3.4.1\n",
            "Summary: State-of-the-Art Text Embeddings\n",
            "Home-page: https://www.SBERT.net\n",
            "Author: \n",
            "Author-email: Nils Reimers <info@nils-reimers.de>, Tom Aarsen <tom.aarsen@huggingface.co>\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface-hub, Pillow, scikit-learn, scipy, torch, tqdm, transformers\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4O9dizW6CsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip show sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a83c9fd-dc1d-412b-acc5-94a356d14269",
        "id": "NVkND_nZ6Eod"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.11 environment at: /usr\u001b[0m\n",
            "Name: sentence-transformers\n",
            "Version: 3.4.1\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface-hub, pillow, scikit-learn, scipy, torch, tqdm, transformers\n",
            "Required-by:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from groq import Groq\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from tqdm import tqdm.auto as tqdm\n"
      ],
      "metadata": {
        "id": "PEEEQkEj2A8x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdfs(pdf_folder):\n",
        "    \"\"\"\n",
        "    Extracts text from all PDF files in the given folder.\n",
        "    \"\"\"\n",
        "    text_data = \"\"\n",
        "    for pdf_file in tqdm(os.listdir(pdf_folder)):\n",
        "        if pdf_file.endswith('.pdf'):\n",
        "            reader = PdfReader(os.path.join(pdf_folder, pdf_file))\n",
        "            for page in reader.pages:\n",
        "                text_data += page.extract_text()\n",
        "    return text_data\n"
      ],
      "metadata": {
        "id": "Ea5ITnyj2-Qt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_chunks(text, chunk_size=500, chunk_overlap=50):\n",
        "    \"\"\"\n",
        "    Splits text into smaller chunks for embedding generation.\n",
        "    \"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    return splitter.split_text(text)\n"
      ],
      "metadata": {
        "id": "m8aMIrhU3xzG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_database(chunks, embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    \"\"\"\n",
        "    Creates a vector database from the given chunks using HuggingFace embeddings.\n",
        "    \"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
        "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
        "    return vector_store\n"
      ],
      "metadata": {
        "id": "42D_ztg337ip"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(query, vector_store, groq_client, model=\"llama-3.3-70b-versatile\"):\n",
        "    \"\"\"\n",
        "    Retrieves relevant chunks from the vector database and generates a response using Groq.\n",
        "    \"\"\"\n",
        "    # Retrieve relevant chunks\n",
        "    docs = vector_store.similarity_search(query, k=5)\n",
        "    context = \" \".join([doc.page_content for doc in tqdm(docs)])\n",
        "\n",
        "    # Generate response\n",
        "    chat_completion = groq_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"Use the following context for your answer: {context}\"},\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ]\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "Bwi3630y4Igh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_groq():\n",
        "    \"\"\"\n",
        "    Initializes the Groq client for the chatbot.\n",
        "    \"\"\"\n",
        "    from google.colab import userdata\n",
        "    xapi_key = userdata.get('GROK')\n",
        "    # Replace \"your_actual_api_key\" with your API key\n",
        "    # client = Groq(api_key=\"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\")\n",
        "    client = Groq(api_key=xapi_key)\n",
        "\n",
        "    return client\n",
        "\n",
        "# Example usage of the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to folder containing PDFs\n",
        "    pdf_folder = \"/content/data\"  # Update with your folder path containing PDFs\n",
        "\n",
        "    # Step 1: Extract text from PDFs\n",
        "    text_data = extract_text_from_pdfs(pdf_folder)\n",
        "\n",
        "    # Step 2: Split text into chunks\n",
        "    chunks = split_text_into_chunks(text_data)\n",
        "\n",
        "    # Step 3: Create a vector database\n",
        "    vector_store = create_vector_database(chunks)\n",
        "\n",
        "    # Step 4: Initialize Groq\n",
        "    groq_client = initialize_groq()  # No arguments passed here\n",
        "\n",
        "    # Step 5: Query the chatbot\n",
        "    query = \"c'est quoi le PMSI SMR?\"\n",
        "    response = chatbot(query, vector_store, groq_client)\n",
        "\n",
        "    print(\"Chatbot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7iKT1DeMShT",
        "outputId": "9e423490-8654-4aaa-e7b7-fa04c2c27650"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: Le PMSI SMR fait référence au Programme de Médicalisation des Systèmes d'Information en Santé pour les Soins de Suite et de Réadaptation (SMR). Il s'agit d'un système de collecte et d'analyse de données sur les activités de soins dispensés dans les établissements de santé publics et privés en France.\n",
            "\n",
            "Le PMSI SMR est un outil de gestion et d'évaluation des soins de suite et de réadaptation, qui vise à améliorer la qualité et l'efficacité des soins dispensés aux patients. Il permet de recueillir et d'analyser des données sur les caractéristiques des patients, les soins dispensés, les durées de séjour, les coûts et les résultats des traitements.\n",
            "\n",
            "Le PMSI SMR est réglementé par l'arrêté du 23 décembre 2016 modifié, qui définit les cadres et les normes pour la collecte et l'analyse des données. Les établissements de santé publics et privés participant au service public hospitalier sont tenus de participer à ce programme, qui a été mis en place à compter du 1er juillet 1998 pour les établissements publics et du 1er juillet 2003 pour les établissements privés.\n",
            "\n",
            "Les données collectées dans le cadre du PMSI SMR sont utilisées pour évaluer la qualité des soins, améliorer la gestion des ressources et optimiser les politiques de santé. Elles sont également utilisées pour établir des statistiques et des indicateurs de performance, qui permettent de comparer les résultats des établissements de santé et de identifier les domaines d'amélioration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comment coder en SMR une reeducation pour un amputé de pied"
      ],
      "metadata": {
        "id": "jaB8_7VE8CzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # Step 5: Query the chatbot\n",
        "    query = \"ccomment coder en SMR une reeducation pour un amputé de pied?\"\n",
        "    response = chatbot(query, vector_store, groq_client)\n",
        "\n",
        "    print(\"Chatbot Response:\", response)"
      ],
      "metadata": {
        "id": "NeT-uNByAxeS",
        "outputId": "9899ee01-d8b5-4b4f-ae23-688b2199c049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: Pour coder en SMR (Système de Médecine de Réadaptation) une rééducation pour un amputé de pied, il faut considérer les différents aspects de la rééducation, tels que l'évaluation, la prise en charge, la rééducation proprement dite, et les éventuels actes de fabrication ou d'adaptation d'appareillage.\n",
            "\n",
            "Voici quelques étapes pour coder en SMR une rééducation pour un amputé de pied :\n",
            "\n",
            "1. **Évaluation** : Il faut évaluer les capacités et les besoins de l'amputé de pied. Cela peut inclure des actes tels que :\n",
            " * Évaluation de la mobilité et de la stabilité (GKR+213 : Séance collective de rééducation du langage oral, mais il faudrait plutôt utiliser un code spécifique pour l'évaluation de la mobilité)\n",
            " * Évaluation de la force et de lacoordination musculaire (BLR+077 : Séance de rééducation oculomotrice, mais il faudrait plutôt utiliser un code spécifique pour l'évaluation de la force et de la coordination musculaire)\n",
            "2. **Prise en charge** : Il faut prendre en charge l'amputé de pied pour améliorer ses capacités et sa qualité de vie. Cela peut inclure des actes tels que :\n",
            " * Rééducation de la marche et de l'équilibre (code spécifique à utiliser)\n",
            " * Rééducation de la force et de la coordination musculaire (code spécifique à utiliser)\n",
            "3. **Rééducation** : Il faut proposer des séances de rééducation pour améliorer les capacités de l'amputé de pied. Cela peut inclure des actes tels que :\n",
            " * Séance de rééducation de la marche et de l'équilibre (code spécifique à utiliser)\n",
            " * Séance de rééducation de la force et de la coordination musculaire (code spécifique à utiliser)\n",
            "4. **Appareillage** : Il faut évaluer les besoins de l'amputé de pied en termes d'appareillage, tels que des prothèses ou des orthèses. Cela peut inclure des actes tels que :\n",
            " * Fabrication d'appareillage (code spécifique à utiliser)\n",
            " * Fourniture et adaptation d'appareillage (code spécifique à utiliser)\n",
            " * Rééducation et apprentissage de l'utilisation d'appareillage (code spécifique à utiliser)\n",
            "\n",
            "Il est important de noter que les codes SMR utilisés doivent être spécifiques à la condition de l'amputé de pied et aux objectifs de la rééducation. Il est recommandé de consulter le catalogue des actes SMR pour trouver les codes les plus appropriés pour chaque étape de la rééducation.\n",
            "\n",
            "Exemples de codes SMR qui pourraient être utilisés pour une rééducation pour un amputé de pied :\n",
            "\n",
            "* GKR+213 : Séance collective de rééducation du langage oral (pas spécifique à l'amputé de pied, mais pourrait être utilisé pour une évaluation de la mobilité)\n",
            "* BLR+077 : Séance de rééducation oculomotrice (pas spécifique à l'amputé de pied, mais pourrait être utilisé pour une évaluation de la force et de la coordination musculaire)\n",
            "* Autres codes spécifiques à l'amputé de pied, tels que :\n",
            " + Rééducation de la marche et de l'équilibre\n",
            " + Rééducation de la force et de la coordination musculaire\n",
            " + Fabrication d'appareillage\n",
            " + Fourniture et adaptation d'appareillage\n",
            " + Rééducation et apprentissage de l'utilisation d'appareillage\n",
            "\n",
            "Il est important de noter que ces codes ne sont pas spécifiques à l'amputé de pied et qu'il est nécessaire de consulter le catalogue des actes SMR pour trouver les codes les plus appropriés pour chaque étape de la rééducation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Step 5: Query the chatbot\n",
        "    query = \"ccomment coder en SMR une reeducation pour un amputé de pied en terme de diagnostics : le MMP et le AE?\"\n",
        "    response = chatbot(query, vector_store, groq_client)\n",
        "\n",
        "    print(\"Chatbot Response:\", response)"
      ],
      "metadata": {
        "id": "rgfE161gA4uq",
        "outputId": "84c703b3-ef3d-4e71-dd38-59a9307bae9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: Pour coder en SMR (Système de Management de la Relation) une rééducation pour un amputé de pied, il est essentiel de choisir les codes diagnostics les plus précis possibles conformément à la Classification Internationale des Maladies (CIM-10) à usage PMSI (Programme de Médicalisation des Systèmes d'Information). Les deux éléments clés à coder sont le MMP (Manifestation Morbide Principale) et l'AE (Affection ou État).\n",
            "\n",
            "1. **MMP (Manifestation Morbide Principale)**:\n",
            "   - Le MMP doit refléter la raison principale pour laquelle le patient a été admis ou traité. Dans le cas d'un amputé de pied en rééducation, le MMP pourrait être lié à la complication ou à l'état qui justifie la rééducation. Par exemple, si l'amputation est la conséquence d'une maladie vasculaire, le MMP pourrait être `I70.2` (Artérosclérose des artères des membres inférieurs) ou un code plus spécifique si disponible.\n",
            "   - Si la rééducation est directement liée à l'amputation elle-même (par exemple, rééducation après amputation), le code MMP pourrait être `Z89.4` (État après amputation de pied), qui reflète l'état du patient après l'amputation.\n",
            "\n",
            "2. **AE (Affection ou État)**:\n",
            "   - L'AE est utilisé pour coder les autres diagnostics ou affections qui sont également traités ou suivis pendant le séjour du patient. Pour un amputé de pied en rééducation, plusieurs codes AE pourraient être pertinents :\n",
            "     - `Z42.8` (État après autre amputation) si l'amputation est la principale raison de la rééducation mais que le code plus spécifique `Z89.4` n'est pas approprié pour certaines raisons (par exemple, si l'amputation concerne une partie différente du pied).\n",
            "     - `M80-M89` (Maladies du système ostéo-articulaire et du tissu musculaire) si des problèmes liés aux os, articulations ou muscles sont également traités pendant la rééducation.\n",
            "     - Codes spécifiques aux complications ou aux affections sous-jacentes qui nécessitent une attention particulière pendant la rééducation, comme les troubles vasculaires (`I70-I79`), les problèmes de peau (`L00-L99`), les affections du système nerveux (`G00-G99`), etc.\n",
            "\n",
            "**Exemple de Codage**:\n",
            "- MMP : `Z89.4` (État après amputation de pied)\n",
            "- AE : `I70.2` (Artérosclérose des artères des membres inférieurs), `M81.0` (Ostéoporose post-ménopausique), `G57.0` (Lésion du nerf sciatique)\n",
            "\n",
            "Il est crucial de respecter les règles de codage établies par la CIM-10 à usage PMSI et de choisir les codes les plus spécifiques et les plus précis possible pour refléter avec exactitude les affections et les traitements du patient. De plus, la documentation médicale doit clairement supporter les codes choisis. La formation et la mise à jour régulière des connaissances en matière de codage sont essentielles pour garantir une qualité élevée et une conformité aux normes et réglementations en vigueur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: rajouter juste les deux fonctions pour sauvegarder et charger le vector store\n",
        "\n",
        "import pickle\n",
        "\n",
        "def save_vector_store(vector_store, filename=\"vector_store.pkl\"):\n",
        "    \"\"\"Saves the vector store to a file using pickle.\"\"\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        pickle.dump(vector_store, f)\n",
        "\n",
        "def load_vector_store(filename=\"vector_store.pkl\"):\n",
        "    \"\"\"Loads the vector store from a file using pickle.\"\"\"\n",
        "    with open(filename, \"rb\") as f:\n",
        "        vector_store = pickle.load(f)\n",
        "    return vector_store\n"
      ],
      "metadata": {
        "id": "L1IS0xyaA0Wi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_vector_store(vector_store)\n"
      ],
      "metadata": {
        "id": "bApt9HqIBWKK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lvcWiy3BqWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Jsqx9F4qBvbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N67ocBWtBxNl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}