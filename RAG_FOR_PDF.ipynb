{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revirevy/RAG_NIX/blob/main/RAG_FOR_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "chatbot\n"
      ],
      "metadata": {
        "id": "ue8iNuly1ZeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q uv PyPDF2 sentence-transformers langchain faiss-cpu groq\n"
      ],
      "metadata": {
        "id": "c48Qeuo71pl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763d44a2-0cd7-40dc-8c9c-a91bc47413df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -U langchain-community -q --system\n"
      ],
      "metadata": {
        "id": "IgDST50w2bad"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from groq import Groq\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n"
      ],
      "metadata": {
        "id": "PEEEQkEj2A8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdfs(pdf_folder):\n",
        "    \"\"\"\n",
        "    Extracts text from all PDF files in the given folder.\n",
        "    \"\"\"\n",
        "    text_data = \"\"\n",
        "    for pdf_file in os.listdir(pdf_folder):\n",
        "        if pdf_file.endswith('.pdf'):\n",
        "            reader = PdfReader(os.path.join(pdf_folder, pdf_file))\n",
        "            for page in reader.pages:\n",
        "                text_data += page.extract_text()\n",
        "    return text_data\n"
      ],
      "metadata": {
        "id": "Ea5ITnyj2-Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_chunks(text, chunk_size=500, chunk_overlap=50):\n",
        "    \"\"\"\n",
        "    Splits text into smaller chunks for embedding generation.\n",
        "    \"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    return splitter.split_text(text)\n"
      ],
      "metadata": {
        "id": "m8aMIrhU3xzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_database(chunks, embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    \"\"\"\n",
        "    Creates a vector database from the given chunks using HuggingFace embeddings.\n",
        "    \"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
        "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
        "    return vector_store\n"
      ],
      "metadata": {
        "id": "42D_ztg337ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_groq():\n",
        "    \"\"\"\n",
        "    Initializes the Groq client for the chatbot.\n",
        "    \"\"\"\n",
        "    client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))  # Replace with your API key\n",
        "    return client\n"
      ],
      "metadata": {
        "id": "AfXzpwq84BKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(query, vector_store, groq_client, model=\"llama-3.3-70b-versatile\"):\n",
        "    \"\"\"\n",
        "    Retrieves relevant chunks from the vector database and generates a response using Groq.\n",
        "    \"\"\"\n",
        "    # Retrieve relevant chunks\n",
        "    docs = vector_store.similarity_search(query, k=5)\n",
        "    context = \" \".join([doc.page_content for doc in docs])\n",
        "\n",
        "    # Generate response\n",
        "    chat_completion = groq_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"Use the following context for your answer: {context}\"},\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ]\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "Bwi3630y4Igh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_groq():\n",
        "    \"\"\"\n",
        "    Initializes the Groq client for the chatbot.\n",
        "    \"\"\"\n",
        "    # Replace \"your_actual_api_key\" with your API key\n",
        "    client = Groq(api_key=\"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\")\n",
        "    return client\n",
        "\n",
        "# Example usage of the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to folder containing PDFs\n",
        "    pdf_folder = \"/content/pdf\"  # Update with your folder path containing PDFs\n",
        "\n",
        "    # Step 1: Extract text from PDFs\n",
        "    text_data = extract_text_from_pdfs(pdf_folder)\n",
        "\n",
        "    # Step 2: Split text into chunks\n",
        "    chunks = split_text_into_chunks(text_data)\n",
        "\n",
        "    # Step 3: Create a vector database\n",
        "    vector_store = create_vector_database(chunks)\n",
        "\n",
        "    # Step 4: Initialize Groq\n",
        "    groq_client = initialize_groq()  # No arguments passed here\n",
        "\n",
        "    # Step 5: Query the chatbot\n",
        "    query = \"What is funtion of ethylene?\"\n",
        "    response = chatbot(query, vector_store, groq_client)\n",
        "\n",
        "    print(\"Chatbot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7iKT1DeMShT",
        "outputId": "c8494fe3-1653-404f-e66f-c11aefc453ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response: According to the text, the functions of ethylene are:\n",
            "\n",
            "1. Breaking seed and bud dormancy, and initiating germination in peanut seeds and sprouting of potato tubers.\n",
            "2. Promoting rapid internode/petiole elongation in deep water rice plants, helping leaves/upper parts of the shoot to remain above water.\n",
            "3. Promoting root growth and root hair formation, increasing the absorption surface of plants.\n",
            "4. Initiating flowering and synchronizing fruit-set apices, developing shoot buds, and young fruits.\n",
            "5. Producing new leaves, chloroplasts in leaves, lateral shoot growth, and adventitious shoot formation.\n",
            "6. Influencing horizontal growth of seedlings, swelling of the axis, and apical hook formation in dicot seedlings.\n",
            "7. Promoting senescence and abscission of plant organs, especially leaves and flowers.\n",
            "8. Enhancing the respiration rate during fruit ripening, also known as the \"respiratory climactic\".\n",
            "9. Inducing flowering in mango.\n",
            "10. Hastening fruit ripening in tomatoes and apples, and accelerating abscission.\n",
            "\n",
            "Overall, ethylene is a plant growth regulator that plays a crucial role in many physiological processes in plants, including growth, development, and senescence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jaB8_7VE8CzZ"
      }
    }
  ]
}